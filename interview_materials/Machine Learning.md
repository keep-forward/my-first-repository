

# Machine Learning 面试题



## 1. HMM（Hidden Markov Model,隐马尔科夫模型）

- ### 使用到HMM问题特征

  1. 问题是基于序列的，如时间序列，状态序列；

  2. 问题中有两类数据：一类序列数据是可以观测到的，即观测序列；另一类数据是不能观测到的，即隐藏状态序列，简称状态序列。

     举例：常用的谷歌输入法等就是采用HMM模型，根据你之前的输入，判断接下来要输入什么给出提示。

- ### 模型定义

  对于HMM模型，首先我们假设Q是所有可能的隐藏状态的集合，V是所有观测状态的集合，即
  $$
  Q=｛q_1,q_2,...,q_n｝,V= ｛v_1,v_2,...,v_m｝
  $$
  其中，N是可能的隐藏状态数，M是所有可能的观察状态数。

  对于一个长度为T的序列，I对应的状态序列，O是对应的观察序列，即
  $$
  I = ｛i_1,i_2,...,i_n｝, O = ｛o_1,o_2,...,o_m｝
  $$
  其中，任意一个隐藏状态it ∈ Q，任意一个观测状态ot ∈ V。

  接着，我们做出以下假设：

  1. #### 齐次马尔科夫链假设

     即任意时刻的隐藏状态只依赖于它前一时刻的隐藏状态。我们得到如果在时刻t的隐藏状态是it=qi，在时刻t+1的隐藏状态是it+1=qj，则从时刻t到时刻t+1的HMM状态转移概率aij可以表示为：
     $$
     a_{ij} = P(i_{t+1} = q_j|i_t=q_i)
     $$
     从而得到马尔科夫链的状态转移矩阵A：
     $$
     A = [a_{ij}]_{N*N}
     $$
     
2. #### 观测独立性假设
  
   即任意时刻的观测状态只仅仅依赖于当前时刻的隐藏状态。如果在时刻t的隐藏状态是it=qj，而对应的观察状态为ot=vk，则该观察状态vk在隐藏状态qj下生成的概率为bj(k)为：
     $$
     b_j(k) = P(o_t = v_k|i_t = q_j)
     $$
     这样bj(k)可以组成观测状态生成的概率矩阵B：
     $$
     B = [b_j(k)]_{N*M}
     $$
     我们再获得一个初始状态t=1的初始状态概率分布π：
     $$
     π = [π(i)]_N, 其中π(i) = P(i_1 = q_i)
     $$

根据上面的两个假设和初始状态就可以确定一个HMM。

隐马尔科夫模型 λ可以用三元符号表示，即
$$
λ = (A, B, π)
$$
 A，B，π称为隐马尔科夫模型的三要素。

- ### 三个经典问题：

1. #### 评估观测序列概率

   - 解释：即给定模型 λ=(A,B,Π) 和观测序列 O={o1,o2,...oT} ，计算在模型λ下观测序列O出现的概率P(O|λ)

   - 对应的解法：前向算法（Forward Algorithm）和后向算法（Backward Algorithm）

   - 前向算法实现：

     1. 计算时刻1的各个隐藏状态前向概率：
        $$
        a_1(i) = π(i)*b_i(o_1),  i=1,2,...,N
        $$

     2. 递推时刻2，3，...，T时刻，也即t=1,2,...,T-1的前向概率
        $$
        a_{t+1} = [Σ_{j=1}^na_t(j)a_{ji}]b_i(o_{t+1}),  i=1,2,...,N
        $$
        
3. 计算最终结果
        $$
        P(O|λ) = \Sigma_{i=1}^Na_t(i)
        $$
     
- 后向算法实现：
   
  1. 初始化时刻T的各个隐藏状态后向概率：
        $$
        B_T(i) = 1,  i=1,2,...,N
        $$
   
  2. 递推时刻T-1，T-2，...，1时刻的后向概率
        $$
        B_t(i) = [Σ_{j=1}^na_{ij}]b_j(o_{t+1})B_{t+1}(i),  i=1,2,...,N
        $$
        
   3. 计算最终结果
     $$
        P(O|λ) = \Sigma_{i=1}^Nπ(i)b_i(o_1)B_1(i)
        $$
        
   
2. #### 预测问题，也称解码问题

   - 解释：即给定模型 λ=(A,B,Π)和观测序列O={o1,o2,...oT}，求给定观测序列条件下，最可能出现的对应的状态序列。
   - 对应的解法：基于动态规划的维特比算法。

3. #### 模型参数学习问题

   - 解释：给定观测序列O={o1,o2,...oT}，估计模型 λ=(A,B,Π)的参数，使得该模型下观测序列的条件概率P(O|λ)最大。

   - 对应的解法：基于EM算法的鲍姆-韦尔奇算法。
