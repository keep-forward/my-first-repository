# 高频问题

## 1. 样本不平衡的解决方法 

**什么是样本不均衡：** 在处理文本分类问题经常会遇到文本不均衡的问题，即训练集中可能会存在某个或者类别下的样本数远大于另一些类别下的样本数目。比如正负样本1:10（类别不平衡比例超过4:1，就会造成偏移） 。

**样本不平衡导致的危害：**样本不均衡将导致样本量少的那一类样本所包含的特征信息太少，很难从中提取规律；即使得到分类模型，也容易产生过度依赖与有限的数据样本而导致过拟合问题。当模型应用到新的数据上时，模型的准确性会很差。

**解决方法：**

1. **扩大数据集：**

   增加数据（一定要有小类样本数据），更多的数据往往战胜更好的算法。 即使再增加小类样本数据时，又增加了大类样本数据，也可以使用放弃一部分大类数据（即对大类数据进行欠采样）来解决。 

2. **尝试其他评价指标：**

   准确度这个评价指标在类别不均衡的分类任务中不能work，甚至进行误导。可以使用精确率、召回率、F1

3. **对数据集进行重采样：**

   - 过抽样（over-sampling）小类样本（不足一万、甚至更少）：

     **扩充小类产生新数据。**SMOTE（Synthetic Minority Over-Sampling Technique）:其思想是合成新的少数类样本，合成的策略是对每个少数样本a，从他的最近邻中随机选一个样本b，然后在a、b之间的连线上随机选一点作为合成的少数类样本。

   - 欠抽样（under-sampling）大类样本（超过1万、十万甚至更多）：

     **压缩大类，产生新数据。**设小类中有N个样本。将大类样本聚类成N个簇，然后使用每个簇的中心组成大类中的N个样本，加上小类中所有的样本进行训练。

4. **尝试产生人工数据样本：**

   一种简单的人工数据样本产生方法是：对该类下的所有样本每个属性特征的取值空间中随机取一个组成新的样本，即属性值随机采样。 你可以使用基于经验对属性值进行随机采样而构造新的人工样本，或者使用类似朴素贝叶斯方法假设各属性之间互相独立进行采样，这样便可得到更多的数据，但是无法保证属性之前的线性关系（如果本身是存在的）。  

5. **尝试不同的分类算法：**

   决策树算法往往在样本不均衡的数据上表现不错。它使用基于类变量的划分规则去创建分类树，因此可以强制的将不同的类别分开。

6. **尝试对模型进行惩罚：**

7. **尝试一个新的角度理解问题：**

8. **尝试创新：**



**整体参考：**  https://blog.csdn.net/qq_33472765/article/details/86561557 